{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "\n",
    "from msc_thesis_functions import *\n",
    "del sys.modules['msc_thesis_functions']\n",
    "from msc_thesis_functions import *\n",
    "\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "\n",
    "import cmocean as cmo\n",
    "\n",
    "import pyproj\n",
    "import verde as vd\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from haversine import haversine, Unit, inverse_haversine\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from cmocean import cm\n",
    "from pydlc import dense_lines\n",
    "import cmasher as cmr\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import fiona\n",
    "import cartopy\n",
    "from cartopy.mpl import geoaxes\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.geodesic import Geodesic\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Polygon, Point, MultiPoint, LineString, mapping\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from time import sleep\n",
    "import rioxarray\n",
    "\n",
    "#Variogram \n",
    "import gstools as gs\n",
    "\n",
    "# import skgstat as skg\n",
    "# from geopy.distance import vincenty\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "#Kriging (pykrige, gstoools, skg)\n",
    "import pykrige.kriging_tools as kt\n",
    "\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "del sys.modules['pykrige.ok']\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "from pykrige.uk import UniversalKriging\n",
    "\n",
    "\n",
    "# Building a 'Blues' colormap where the lower end (white) is transperant\n",
    "ncolors = 256\n",
    "color_array = plt.get_cmap('Greys')(range(ncolors))\n",
    "color_array[:,-1] = np.linspace(0.0,1.0,ncolors)\n",
    "map_object = LinearSegmentedColormap.from_list(name='Greys_alpha',colors=color_array)\n",
    "\n",
    "# register this new colormap with matplotlib\n",
    "# plt.colormaps.register(cmap=map_object)\n",
    "\n",
    "from pyfonts import load_font\n",
    "\n",
    "# font = load_font(\n",
    "#    \"https://github.com/google/fonts/blob/main/ofl/roboto/Roboto[wdth,wght].ttf?raw=true\"\n",
    "# )\n",
    "\n",
    "from pyproj import Transformer\n",
    "transformer = Transformer.from_crs(4326, 3413, always_xy=True)\n",
    "import skgstat as skg\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extent_xy(x,y):\n",
    "    return (min(x), min(y), max(x), max(y))\n",
    "\n",
    "def measurement_bounds_with_dist(dist, x, y):\n",
    "    \"\"\"\n",
    "    Using a distance (e.g. from a predetermined variogram model (with length scale)) to construct a polygon that represents the area \n",
    "    within the extent (from min and max of x and y) where the point-measurements are within the given distance (e.g. being still auto-correlated).    \n",
    "     \n",
    "    Args:\n",
    "        dist (float): Buffer distance around points\n",
    "        x (float): Locations in x-direction [m]\n",
    "        y (float):  Location in y-direction [m]\n",
    "    \n",
    "    Returns:\n",
    "        A shapely.Polygon that outlines the measurement boundaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    circles = [Point(xi,yi).buffer(dist) for xi, yi in list(zip(x, y))]\n",
    "    union = shapely.union_all(circles)\n",
    "\n",
    "    # try: \n",
    "    #     areas = []\n",
    "    #     for shp in union.geoms:\n",
    "    #         areas.append(shp.area)\n",
    "\n",
    "    #     maxind = np.argmax(areas)\n",
    "    #     union = union.geoms[maxind]\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # intersec = Polygon.intersection(union,  Polygon.from_bounds(*get_extent_xy(x, y)))\n",
    "    return union\n",
    "\n",
    "\n",
    "def plot_polygon(ax, poly, **kwargs):\n",
    "    path = Path.make_compound_path(\n",
    "        Path(np.asarray(poly.exterior.coords)[:, :2]),\n",
    "        *[Path(np.asarray(ring.coords)[:, :2]) for ring in poly.interiors])\n",
    "\n",
    "    patch = PathPatch(path, **kwargs)\n",
    "    collection = PatchCollection([patch], **kwargs)\n",
    "    \n",
    "    ax.add_collection(collection, autolim=True)\n",
    "    ax.autoscale_view()\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####### Setup #######\n",
    "extent = (272, 79.723705,274, 80.576499) #minlon, minlat, maxlon, maxlat for EUREKA 2014 (and 2016?)\n",
    "\n",
    "year = '2014'\n",
    "\n",
    "campaigns = [\n",
    "    # 'CRYOVEX2014',\n",
    "    # 'EUREKA2016',\n",
    "    'EUREKA2014',\n",
    "]\n",
    "\n",
    "paths_MP = [\n",
    "    # '/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/CryoVEx2014_SEAICE_GROUNDDATA_V1/NORD_CAMP_TRANSECT.csv', #CRYOVEX 2014\n",
    "    '/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/ECCCEureka2014.h5', #EUREKA 2014\n",
    "    # '/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/Eureka/ECCC_2016_Eureka_Magnaprobe.csv' #EUREKA 2016\n",
    "]\n",
    "\n",
    "# output_path = '/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/Eureka/krigging3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting the 2014 transect outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2014':\n",
    "    f = h5py.File(paths_MP[0], 'r')\n",
    "    group = f['eureka_data']\n",
    "    data = group['magnaprobe']\n",
    "    df_df = pd.DataFrame({'lat':data['latitude'][()], 'lon':data['longitude'][()], 'snow_depth':data['snow_depth'][()], 'site_id':data['site_id'][()]})\n",
    "    df_df.loc[df_df['lon'] < 0, 'lon'] += 360\n",
    "    df_df['ice_type'] = ['fyi']*len(df_df)\n",
    "    \n",
    "df_f = df_df.loc[df_df['site_id'] == 1]\n",
    "df_f['x'], df_f['y'] = transformer.transform(df_f['lon'].values, df_f['lat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    }
   ],
   "source": [
    "shape_path = f'/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/Eureka/grid_extents_v4'\n",
    "site = 'transect'\n",
    "dist = 20\n",
    "intersec = measurement_bounds_with_dist(dist, df_f['x'], df_f['y'])\n",
    "gdf = gpd.GeoDataFrame(geometry=[intersec])\n",
    "gdf.to_file(os.path.join(shape_path, f'{campaigns[0]}_{site}_measurement_bounds.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load magnaprobe in situ data\n",
    "path_MP = paths_MP[0]\n",
    "\n",
    "filetype = path_MP.split('.')[1]\n",
    "df_dict = open_data(path_MP, filetype=filetype, mode='dict', instrument='MP')\n",
    "\n",
    "if year == '2014':\n",
    "    f = h5py.File(path_MP, 'r')\n",
    "    group = f['eureka_data']\n",
    "    data = group['magnaprobe']\n",
    "    df_df = pd.DataFrame({'lat':data['latitude'][()], 'lon':data['longitude'][()], 'snow_depth':data['snow_depth'][()], 'site_id':data['site_id'][()]})\n",
    "    df_df.loc[df_df['lon'] < 0, 'lon'] += 360\n",
    "    df_df['ice_type'] = ['fyi']*len(df_df)\n",
    "    \n",
    "elif year == '2016':\n",
    "    for key in df_dict.keys():\n",
    "        if key == list(df_dict.keys())[0]:\n",
    "            df_df = df_dict[key]\n",
    "        else:\n",
    "            df_df = pd.concat([df_df, df_dict[key]])\n",
    "            \n",
    "df_df['x'], df_df['y'] = transformer.transform(df_df['lon'], df_df['lat'])\n",
    "\n",
    "sites = df_df['site_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do kriging: False\n",
      "Exact kriging: True\n",
      "Kriging length scale: effective\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c40ac4db30427c90aa679789c8dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid3\n",
      "R2, undeformed: 0.98\n",
      "R2, deformed: 0.81\n",
      "Variograms estimated...\n",
      "both\n",
      "Length scales: undeformed: 6.77, deformed: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23886 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n",
      "grid4\n",
      "R2, undeformed: 0.99\n",
      "R2, deformed: -0.00\n",
      "Variograms estimated...\n",
      "fully_undeformed\n",
      "Length scales: undeformed: 2.92, deformed: 330.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24712 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n",
      "grid5\n",
      "R2, undeformed: 0.99\n",
      "R2, deformed: 0.98\n",
      "Variograms estimated...\n",
      "both\n",
      "Length scales: undeformed: 4.20, deformed: 5.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29056 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n",
      "grid6\n",
      "R2, undeformed: 0.99\n",
      "R2, deformed: -0.00\n",
      "Variograms estimated...\n",
      "fully_undeformed\n",
      "Length scales: undeformed: 3.83, deformed: 675.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28019 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n",
      "grid7\n",
      "R2, undeformed: 0.99\n",
      "R2, deformed: 0.40\n",
      "Variograms estimated...\n",
      "fully_undeformed\n",
      "Length scales: undeformed: 11.91, deformed: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28113 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n",
      "grid8\n",
      "R2, undeformed: 0.98\n",
      "R2, deformed: 0.99\n",
      "Variograms estimated...\n",
      "both\n",
      "Length scales: undeformed: 3.17, deformed: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/landlab/lib/python3.10/site-packages/pyogrio/geopandas.py:662: UserWarning: 'crs' was not provided.  The output dataset will not have projection information defined and may not be usable in other systems.\n",
      "  write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13368 datapoints to do kriging on... \n",
      "File saved, done... \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# stepsize = 1 \n",
    "# instrument_error = 0.007 # MagnaProbe instrument error: 7 mm\n",
    "exact_values = True\n",
    "kriging = False\n",
    "length_scale = 'effective' #could alse be \"effective\"\n",
    "print(f'Do kriging: {kriging}')\n",
    "print(f'Exact kriging: {exact_values}')\n",
    "print(f'Kriging length scale: {length_scale}')\n",
    "\n",
    "dist = 50 if year == '2014' else 10\n",
    "\n",
    "write_measurement_bounds = True\n",
    "shape_path = f'/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/Eureka/grid_extents_v4'\n",
    "\n",
    "output_path = f'/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/Eureka/krigging_onATMgrid_v5_exact{str(exact_values)}'\n",
    "topography_grid_path = '/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Data/OIB/ATM_gridded/gridding_v7'\n",
    "plotting_path = output_path #'/Users/torka/Library/CloudStorage/OneDrive-Personal/MarineSciences/MasterThs-T/Plots/20241213/automated_kriging_plots2'\n",
    "\n",
    "# site = 'grid3'\n",
    "\n",
    "for site in tqdm(sites[2:]): #sites\n",
    "    print(site)\n",
    "    \n",
    "    df_f = df_df.loc[df_df['site_id'] == site]\n",
    "    df_f.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    grid = xr.open_dataset(os.path.join(topography_grid_path,f'{campaigns[0]}_ATM_gridded_{site}.nc'))\n",
    "    \n",
    "    # Step 1: Find the nearest grid indices\n",
    "    # Convert xarray coordinates to NumPy arrays\n",
    "    grid_x = grid[\"easting\"].values\n",
    "    grid_y = grid[\"northing\"].values\n",
    "\n",
    "    # Find the closest index for each point\n",
    "    df_f[\"x_idx\"] = np.searchsorted(grid_x, df_f[\"x\"]) - 1\n",
    "    df_f[\"y_idx\"] = np.searchsorted(grid_y, df_f[\"y\"]) - 1\n",
    "\n",
    "    # Ensure indices are within bounds\n",
    "    df_f[\"x_idx\"] = df_f[\"x_idx\"].clip(0, len(grid_x) - 1)\n",
    "    df_f[\"y_idx\"] = df_f[\"y_idx\"].clip(0, len(grid_y) - 1)\n",
    "\n",
    "    # Step 2: Retrieve the classification value from the grid\n",
    "    classification = grid[\"classes\"].values\n",
    "    df_f[\"classes\"] = classification[df_f[\"y_idx\"], df_f[\"x_idx\"]]\n",
    "    \n",
    "    # seperate dataframe into undeformed/ deformed\n",
    "    df_f_undeformed = df_f.loc[df_f['classes'] == 0]\n",
    "    df_f_deformed = df_f.loc[df_f['classes'] == 1]\n",
    "\n",
    "    # construct grids for later use\n",
    "    grid_x, grid_y = grid['easting'].values, grid['northing'].values\n",
    "    grid_xx, grid_yy = np.meshgrid(grid_x, grid_y, indexing='xy')\n",
    "    grid_x, grid_y = grid_xx.flatten(), grid_yy.flatten()\n",
    "\n",
    "    grid_inds = np.arange(len(grid_x))\n",
    "    \n",
    "    elevs = grid['elevation'].values.flatten()\n",
    "    mask = ~np.isnan(elevs)\n",
    "    \n",
    "    #construct masked grid axis and indices\n",
    "    grid_x_masked, grid_y_masked = grid_x[mask], grid_y[mask]\n",
    "    grid_inds_masked = grid_inds[mask]\n",
    "    \n",
    "    \n",
    "    # mask furhter into deformed/ undeformed based on classes\n",
    "    classes = grid['classes'].values.flatten()\n",
    "    classes = classes[mask]\n",
    "\n",
    "    grid_undeformed_x = grid_x_masked[classes == 0]\n",
    "    grid_undeformed_y = grid_y_masked[classes == 0]\n",
    "\n",
    "    grid_deformed_x = grid_x_masked[classes == 1]\n",
    "    grid_deformed_y = grid_y_masked[classes == 1]\n",
    "\n",
    "    grid_inds_undeformed  = grid_inds_masked[classes == 0]\n",
    "    grid_inds_deformed  = grid_inds_masked[classes == 1]\n",
    "\n",
    "\n",
    "    #calculate mean seperation distance between consecutive data points\n",
    "    dists = cdist(np.column_stack([df_f['x'], df_f['y']]), np.column_stack([df_f['x'], df_f['y']]))\n",
    "    dists[dists==0] = np.nan\n",
    "    mean_distance = np.nanmean(dists[np.arange(1, len(df_f_undeformed)), np.arange(len(df_f_undeformed) - 1)])\n",
    "\n",
    "    \n",
    "    # construct bins for variogram estimation \n",
    "    dists = cdist(np.column_stack([df_f_undeformed['x'], df_f_undeformed['y']]), np.column_stack([df_f_undeformed['x'], df_f_undeformed['y']]))\n",
    "    dists[dists==0] = np.nan\n",
    "    bins_undeformed = np.arange(np.nanmin(dists), np.nanquantile(dists,.15), mean_distance)\n",
    "    \n",
    "    dists = cdist(np.column_stack([df_f_deformed['x'], df_f_deformed['y']]), np.column_stack([df_f_deformed['x'], df_f_deformed['y']]))\n",
    "    dists[dists==0] = np.nan\n",
    "    bins_deformed = np.arange(np.nanmin(dists), np.nanquantile(dists,.15), mean_distance/2)\n",
    "    \n",
    "    \n",
    "    # calculate variograms\n",
    "    flag = 'both'\n",
    "    \n",
    "    try:\n",
    "        bin_center_undeformed, vario_undeformed, counts_undeformed = gs.vario_estimate((df_f_undeformed['y'], df_f_undeformed['x']), df_f_undeformed['snow_depth'],\n",
    "                                        return_counts=True,\n",
    "                                        bin_edges=bins_undeformed\n",
    "                                        )\n",
    "        model_undeformed = gs.Matern()\n",
    "        _,_,r2_undeformed = model_undeformed.fit_variogram(bin_center_undeformed, vario_undeformed,\n",
    "                                    init_guess={\"len_scale\": 10},\n",
    "                                    return_r2=True\n",
    "                                    )\n",
    "        variogram_plot(bin_center_undeformed, vario_undeformed, counts_undeformed, model_undeformed, r2_undeformed, save_path=os.path.join(plotting_path, f'{campaigns[0]}_{site}_variogram_undeformed.png'))\n",
    "        print(f'R2, undeformed: {r2_undeformed:.2f}')\n",
    "        if r2_undeformed < .7:\n",
    "            flag = 'fully_deformed'\n",
    "    except:\n",
    "        flag = 'fully_deformed'\n",
    "\n",
    "\n",
    "    try:\n",
    "        bin_center_deformed, vario_deformed, counts_deformed = gs.vario_estimate((df_f_deformed['y'], df_f_deformed['x']), df_f_deformed['snow_depth'],\n",
    "                                            return_counts=True,\n",
    "                                            bin_edges=bins_deformed\n",
    "                                            )\n",
    "        model_deformed = gs.Matern()\n",
    "        _,_, r2_deformed = model_deformed.fit_variogram(bin_center_deformed, vario_deformed,\n",
    "                                    init_guess={\"len_scale\": 10},\n",
    "                                    return_r2=True\n",
    "                                    )\n",
    "\n",
    "        variogram_plot(bin_center_deformed, vario_deformed, counts_deformed, model_deformed, r2_deformed, save_path=os.path.join(plotting_path, f'{campaigns[0]}_{site}_variogram_deformed.png'))\n",
    "        print(f'R2, deformed: {r2_deformed:.2f}')     \n",
    "        if r2_deformed < .7:\n",
    "            flag = 'fully_undeformed'\n",
    "    except:\n",
    "        flag = 'fully_undeformed'\n",
    "        \n",
    "    print('Variograms estimated...')\n",
    "    print(flag)\n",
    "    \n",
    "    if length_scale == 'effective':\n",
    "            undeformed_length_scale = model_undeformed.len_scale\n",
    "            deformed_length_scale = model_deformed.len_scale\n",
    "    else:\n",
    "        undeformed_length_scale = model_undeformed.percentile_scale(float(length_scale))\n",
    "        deformed_length_scale = model_deformed.percentile_scale(float(length_scale))\n",
    "    \n",
    "    print(f'Length scales: undeformed: {undeformed_length_scale:.2f}, deformed: {deformed_length_scale:.2f}')\n",
    "    if flag == 'both':\n",
    "        \n",
    "       \n",
    "        # compute grids to perform kriging on (masking out points that are beyond the modelled variogram range)\n",
    "        intersec = measurement_bounds_with_dist(dist, df_f['x'], df_f['y'])\n",
    "        intersec = shapely.buffer(intersec, -dist)\n",
    "        union = measurement_bounds_with_dist(min(undeformed_length_scale, deformed_length_scale), df_f['x'], df_f['y'])\n",
    "\n",
    "\n",
    "        geoms_final = []\n",
    "        try:\n",
    "            geoms1 = [geom for geom in intersec.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms1 = [intersec]\n",
    "            \n",
    "        try:\n",
    "            geoms2 = [geom for geom in union.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms2 = [union] \n",
    "\n",
    "        for geom1 in geoms1:\n",
    "            for geom2 in geoms2:\n",
    "                intersec2 = shapely.intersection(geom1, geom2)\n",
    "                \n",
    "                if intersec2.area > 100:\n",
    "                    geoms_final.append(intersec2)\n",
    "        \n",
    "        if write_measurement_bounds:\n",
    "            gdf = gpd.GeoDataFrame(geometry=geoms_final)\n",
    "            gdf.to_file(os.path.join(shape_path, f'{campaigns[0]}_{site}_measurement_bounds.shp'))\n",
    "            \n",
    "        # undeformed\n",
    "        points_undeformed = [Point(xi,yi) for xi, yi in list(zip(grid_undeformed_x, grid_undeformed_y))]\n",
    "        di_undeformed = points_in_single_poly(geoms_final, points_undeformed)\n",
    "        indices_undeformed = np.unique(np.concatenate([np.array(di_undeformed[key]) for key in di_undeformed.keys()]))\n",
    "        grid_undeformed_x, grid_undeformed_y = grid_undeformed_x[indices_undeformed], grid_undeformed_y[indices_undeformed]\n",
    "        grid_inds_undeformed = grid_inds_undeformed[indices_undeformed]\n",
    "        \n",
    "        # deformed\n",
    "        points_deformed = [Point(xi,yi) for xi, yi in list(zip(grid_deformed_x, grid_deformed_y))]\n",
    "        di_deformed = points_in_single_poly(geoms_final, points_deformed)\n",
    "        indices_deformed = np.unique(np.concatenate([np.array(di_deformed[key]) for key in di_deformed.keys()]))\n",
    "        grid_deformed_x, grid_deformed_y = grid_deformed_x[indices_deformed], grid_deformed_y[indices_deformed]\n",
    "        grid_inds_deformed = grid_inds_deformed[indices_deformed]\n",
    "        \n",
    "        print(f'{len(grid_inds_deformed) + len(grid_inds_undeformed)} datapoints to do kriging on... ')\n",
    "\n",
    "        if kriging == True:\n",
    "\n",
    "            # perform kriging\n",
    "            OK_undeformed = OrdinaryKriging(df_f_undeformed['x'], df_f_undeformed['y'], df_f_undeformed['snow_depth'],\n",
    "                    variogram_model=gs.Matern(dim=2, len_scale=undeformed_length_scale, nugget=model_undeformed.nugget, var=model_undeformed.var),\n",
    "                    exact_values=exact_values,\n",
    "                    )\n",
    "            z_undeformed, ss_undeformed = OK_undeformed.execute(\"points\", grid_undeformed_x, grid_undeformed_y)\n",
    "\n",
    "            OK_deformed = OrdinaryKriging(df_f_deformed['x'], df_f_deformed['y'], df_f_deformed['snow_depth'],\n",
    "                    variogram_model=gs.Matern(dim=2, len_scale=deformed_length_scale, nugget=model_deformed.nugget, var=model_deformed.var),\n",
    "                    exact_values=False\n",
    "            )\n",
    "            z_deformed, ss_deformed = OK_deformed.execute(\"points\", grid_deformed_x, grid_deformed_y)\n",
    "            print('Kriging done... ')\n",
    "            \n",
    "            # put the results onto the ATM grid\n",
    "            z_gridded = np.empty_like(grid_x)\n",
    "            z_gridded[:] = np.nan\n",
    "            z_gridded[grid_inds_undeformed] = z_undeformed\n",
    "            z_gridded[grid_inds_deformed] = z_deformed\n",
    "            z_gridded = z_gridded.reshape(np.shape(grid_xx))\n",
    "\n",
    "\n",
    "            ss_gridded = np.empty_like(grid_x)\n",
    "            ss_gridded[:] = np.nan\n",
    "            ss_gridded[grid_inds_undeformed] = ss_undeformed\n",
    "            ss_gridded[grid_inds_deformed] = ss_deformed\n",
    "            ss_gridded = ss_gridded.reshape(np.shape(grid_xx))\n",
    "            \n",
    "            # plot the results\n",
    "            fig, ax = plt.subplots(2,2, figsize=(10,10), dpi=200, sharex=True, sharey=True, constrained_layout=True)\n",
    "            ax = ax.ravel()\n",
    "            # scat= ax.pcolormesh(grid_xx, grid_yy, ss_gridded)\n",
    "            scat = ax[0].scatter(grid_undeformed_x, grid_undeformed_y, c=z_undeformed,  s=.1, cmap='Blues', vmin=0, vmax=.8)\n",
    "            scat = ax[2].scatter(grid_deformed_x, grid_deformed_y, c=z_deformed,  s=.1, cmap='Blues', vmin=0, vmax=.8)\n",
    "            fig.colorbar(scat, ax=ax[0::2], shrink=.5, label='Snow depth [m]')\n",
    "\n",
    "\n",
    "            scat = ax[1].scatter(grid_undeformed_x, grid_undeformed_y, c=ss_undeformed,  s=.1, cmap=cmr.amber, vmin=0, vmax=.075)\n",
    "            scat = ax[3].scatter(grid_deformed_x, grid_deformed_y, c=ss_deformed,  s=.1, cmap=cmr.amber, vmin=0, vmax=.075)\n",
    "            fig.colorbar(scat, ax=ax[1::2], shrink=.5, label='Snow depth uncertainty [m]')\n",
    "\n",
    "\n",
    "            ax[0].set_ylabel('Undeformed',size=16)\n",
    "            ax[0].set_title('Snow depth',size=16)\n",
    "\n",
    "            ax[2].set_ylabel('Deformed',size=16)\n",
    "            ax[1].set_title('Kriging uncertainty',size=16)\n",
    "\n",
    "            for i in range(len(ax)):\n",
    "                ax[i].set_xticks([])  \n",
    "                ax[i].set_yticks([])  \n",
    "                ax[i].set_aspect('equal')\n",
    "                \n",
    "            fig.suptitle(f'{campaigns[0]}_{site}')\n",
    "            plt.savefig(os.path.join(plotting_path, f'{campaigns[0]}_{site}_kriging_results.png'))\n",
    "            plt.close()\n",
    "        \n",
    "     # if deformed does not give good results, we krig the whole field with the results from undeformed (in the final file, the classes are still given, so we can judge whether we like the fit)\n",
    "    elif flag == 'fully_undeformed':\n",
    "        \n",
    "        intersec = measurement_bounds_with_dist(dist, df_f['x'], df_f['y'])\n",
    "        \n",
    "        intersec = shapely.buffer(intersec, -dist)\n",
    "        union = measurement_bounds_with_dist(undeformed_length_scale, df_f['x'], df_f['y'])\n",
    "\n",
    "        geoms_final = []\n",
    "        try:\n",
    "            geoms1 = [geom for geom in intersec.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms1 = [intersec]\n",
    "            \n",
    "        try:\n",
    "            geoms2 = [geom for geom in union.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms2 = [union] \n",
    "\n",
    "        for geom1 in geoms1:\n",
    "            for geom2 in geoms2:\n",
    "                intersec2 = shapely.intersection(geom1, geom2)\n",
    "                \n",
    "                if intersec2.area > 100:\n",
    "                    geoms_final.append(intersec2)\n",
    "                    \n",
    "        if write_measurement_bounds:\n",
    "            gdf = gpd.GeoDataFrame(geometry=geoms_final)\n",
    "            gdf.to_file(os.path.join(shape_path, f'{campaigns[0]}_{site}_measurement_bounds.shp'))\n",
    "            \n",
    "        points = [Point(xi,yi) for xi, yi in list(zip(grid_x_masked, grid_y_masked))]\n",
    "        di = points_in_single_poly(geoms_final, points)\n",
    "        indices = np.unique(np.concatenate([np.array(di[key]) for key in di.keys()]))\n",
    "        grid_x_masked, grid_y_masked = grid_x_masked[indices], grid_y_masked[indices]\n",
    "        grid_inds_masked = grid_inds_masked[indices]\n",
    "        \n",
    "        \n",
    "        # intersec = measurement_bounds_with_dist(model_undeformed.len_scale, df_f['x'], df_f['y'])\n",
    "        # points = [Point(xi,yi) for xi, yi in list(zip(grid_x_masked, grid_y_masked))]\n",
    "        # indices = points_in_single_poly(intersec, points)[0]\n",
    "        # grid_x_masked, grid_y_masked = grid_x_masked[indices], grid_y_masked[indices]\n",
    "        # grid_inds_masked = grid_inds_masked[indices]\n",
    "        \n",
    "        \n",
    "        print(f'{len(grid_inds_masked)} datapoints to do kriging on... ')\n",
    "        \n",
    "        if kriging == True:\n",
    "            # perform kriging\n",
    "            OK= OrdinaryKriging(df_f['x'], df_f['y'], df_f['snow_depth'],\n",
    "                    variogram_model=gs.Matern(dim=2, len_scale=undeformed_length_scale, nugget=model_undeformed.nugget, var=model_undeformed.var),\n",
    "                    exact_values=exact_values,\n",
    "                    )\n",
    "            z, ss = OK.execute(\"points\", grid_x_masked, grid_y_masked)\n",
    "            print('Kriging done... ')\n",
    "            \n",
    "            z_gridded = np.empty_like(grid_x)\n",
    "            z_gridded[:] = np.nan\n",
    "            z_gridded[grid_inds_masked] = z\n",
    "            z_gridded = z_gridded.reshape(np.shape(grid_xx))\n",
    "\n",
    "\n",
    "            ss_gridded = np.empty_like(grid_x)\n",
    "            ss_gridded[:] = np.nan\n",
    "            ss_gridded[grid_inds_masked] = ss\n",
    "            ss_gridded = ss_gridded.reshape(np.shape(grid_xx))\n",
    "            \n",
    "            # plot the results\n",
    "            fig, ax = plt.subplots(1,2, figsize=(10,5), dpi=200, sharex=True, sharey=True, constrained_layout=True)\n",
    "            ax = ax.ravel()\n",
    "            scat = ax[0].scatter(grid_x_masked, grid_y_masked, c=z,  s=.1, cmap='Blues', vmin=0, vmax=.8)\n",
    "            fig.colorbar(scat, ax=ax[0], shrink=.5, label='Snow depth [m]')\n",
    "\n",
    "\n",
    "            scat = ax[1].scatter(grid_x_masked, grid_y_masked, c=ss,  s=.1, cmap=cmr.amber, vmin=0, vmax=.075)\n",
    "            fig.colorbar(scat, ax=ax[1::2], shrink=.5, label='Snow depth uncertainty [m]')\n",
    "\n",
    "\n",
    "            ax[0].set_title('Snow depth',size=16)\n",
    "            ax[1].set_title('Kriging uncertainty',size=16)\n",
    "\n",
    "            for i in range(len(ax)):\n",
    "                ax[i].set_xticks([])  \n",
    "                ax[i].set_yticks([])  \n",
    "                ax[i].set_aspect('equal')\n",
    "                \n",
    "            fig.suptitle(f'{campaigns[0]}_{site}')\n",
    "            plt.savefig(os.path.join(plotting_path, f'{campaigns[0]}_{site}_kriging_results.png'))\n",
    "            plt.close()\n",
    "    \n",
    "    \n",
    "     # if undeformed does not give good results, we krig the whole field with the results from deformed (in the final file, the classes are still given, so we can judge whether we like the fit)\n",
    "    elif flag == 'fully_deformed':\n",
    "        \n",
    "        \n",
    "        intersec = measurement_bounds_with_dist(dist, df_f['x'], df_f['y'])\n",
    "        if write_measurement_bounds:\n",
    "            gdf = gpd.GeoDataFrame(geometry=[intersec])\n",
    "            gdf.to_file(os.path.join(shape_path, f'{campaigns[0]}_{site}_measurement_bounds.shp'))\n",
    "        intersec = shapely.buffer(intersec, -dist)\n",
    "        union = measurement_bounds_with_dist(deformed_length_scale, df_f['x'], df_f['y'])\n",
    "\n",
    "        geoms_final = []\n",
    "        try:\n",
    "            geoms1 = [geom for geom in intersec.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms1 = [intersec]\n",
    "            \n",
    "        try:\n",
    "            geoms2 = [geom for geom in union.geoms if geom.area > 100]\n",
    "        except:\n",
    "            geoms2 = [union] \n",
    "\n",
    "        for geom1 in geoms1:\n",
    "            for geom2 in geoms2:\n",
    "                intersec2 = shapely.intersection(geom1, geom2)\n",
    "                \n",
    "                if intersec2.area > 100:\n",
    "                    geoms_final.append(intersec2)\n",
    "        \n",
    "\n",
    "        if write_measurement_bounds:\n",
    "            gdf = gpd.GeoDataFrame(geometry=geoms_final)\n",
    "            gdf.to_file(os.path.join(shape_path, f'{campaigns[0]}_{site}_measurement_bounds.shp'))\\\n",
    "                \n",
    "        points = [Point(xi,yi) for xi, yi in list(zip(grid_x_masked, grid_y_masked))]\n",
    "        di = points_in_single_poly(geoms_final, points)\n",
    "        indices = np.unique(np.concatenate([np.array(di[key]) for key in di.keys()]))\n",
    "        grid_x_masked, grid_y_masked = grid_x_masked[indices], grid_y_masked[indices]\n",
    "        grid_inds_masked = grid_inds_masked[indices]\n",
    "        \n",
    "        # intersec = measurement_bounds_with_dist(model_deformed.len_scale, df_f['x'], df_f['y'])\n",
    "        # points = [Point(xi,yi) for xi, yi in list(zip(grid_x_masked, grid_y_masked))]\n",
    "        # indices = points_in_single_poly(intersec, points)[0]\n",
    "        # grid_x_masked, grid_y_masked = grid_x_masked[indices], grid_y_masked[indices]\n",
    "        # grid_inds_masked = grid_inds_masked[indices]\n",
    "        print(f'{len(grid_inds_masked)} datapoints to do kriging on... ')\n",
    "        \n",
    "        # perform kriging\n",
    "        if kriging == True:\n",
    "            OK= OrdinaryKriging(df_f['x'], df_f['y'], df_f['snow_depth'],\n",
    "                    variogram_model=gs.Matern(dim=2, len_scale=deformed_length_scale, nugget=model_deformed.nugget, var=model_deformed.var),\n",
    "                    exact_values=exact_values,\n",
    "                    )\n",
    "            z, ss = OK.execute(\"points\", grid_x_masked, grid_y_masked)\n",
    "            print('Kriging done... ')\n",
    "            \n",
    "            z_gridded = np.empty_like(grid_x)\n",
    "            z_gridded[:] = np.nan\n",
    "            z_gridded[grid_inds_masked] = z\n",
    "            z_gridded = z_gridded.reshape(np.shape(grid_xx))\n",
    "\n",
    "\n",
    "            ss_gridded = np.empty_like(grid_x)\n",
    "            ss_gridded[:] = np.nan\n",
    "            ss_gridded[grid_inds_masked] = ss\n",
    "            ss_gridded = ss_gridded.reshape(np.shape(grid_xx))\n",
    "            \n",
    "            \n",
    "            # plot the results\n",
    "            fig, ax = plt.subplots(1,2, figsize=(10,5), dpi=200, sharex=True, sharey=True, constrained_layout=True)\n",
    "            ax = ax.ravel()\n",
    "            scat = ax[0].scatter(grid_x_masked, grid_y_masked, c=z,  s=.1, cmap='Blues', vmin=0, vmax=.8)\n",
    "            fig.colorbar(scat, ax=ax[0], shrink=.5, label='Snow depth [m]')\n",
    "\n",
    "\n",
    "            scat = ax[1].scatter(grid_x_masked, grid_y_masked, c=ss,  s=.1, cmap=cmr.amber, vmin=0, vmax=.075)\n",
    "            fig.colorbar(scat, ax=ax[1::2], shrink=.5, label='Snow depth uncertainty [m]')\n",
    "\n",
    "\n",
    "            ax[0].set_title('Snow depth',size=16)\n",
    "            ax[1].set_title('Kriging uncertainty',size=16)\n",
    "\n",
    "            for i in range(len(ax)):\n",
    "                ax[i].set_xticks([])  \n",
    "                ax[i].set_yticks([])  \n",
    "                ax[i].set_aspect('equal')\n",
    "            fig.suptitle(f'{campaigns[0]}_{site}')\n",
    "            plt.savefig(os.path.join(plotting_path, f'{campaigns[0]}_{site}_kriging_results.png'))\n",
    "            plt.close()\n",
    "        \n",
    "    \n",
    "    #construct xarray dataset to save it \n",
    "    if kriging == True:\n",
    "        ds = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                snow_depth=([\"northing\", \"easting\"], z_gridded, {'description':'Snow depth, interpolated via ordinary kriging (pyKrige) in the respective classes','units':'m'}),\n",
    "                snow_depth_uncertainty=([\"northing\", \"easting\"], ss_gridded, {'description':'Kriging uncertainty of the snow depth','units':'m'}),\n",
    "                classes=([\"northing\", \"easting\"], grid['classes'].values, {'0':'undeformed', '1':'deformed'}),  \n",
    "                                \n",
    "            ),\n",
    "            coords=dict(\n",
    "                easting=(\"easting\", grid['easting'].values),\n",
    "                northing=(\"northing\", grid['northing'].values),\n",
    "\n",
    "            ),\n",
    "            attrs=dict(\n",
    "                campaign=campaigns[0],\n",
    "                site=site,\n",
    "                ice_type=df_f['ice_type'][0],\n",
    "                kriging_flag=flag,\n",
    "                instrument='MagnaProbe (MP)',\n",
    "                data_file='ECCCEureka2014.h5' if year == '2014' else 'ECCC_2016_Eureka_Magnaprobe.csv',\n",
    "                data_source='https://github.com/kingjml/ECCC-Eureka-2016-OpenData' if year == '2016' else 'https://github.com/kingjml/ECCC-Eureka-2014-Snow-on-Sea-Ice-Campaign',\n",
    "                grid_file=os.path.join(topography_grid_path,f'{campaigns[0]}_ATM_gridded_{site}.nc'),\n",
    "                horizontal_resolution=1,\n",
    "                length_scale=length_scale,\n",
    "                variogram_model=model_deformed.name,\n",
    "                undeformed_range=model_undeformed.len_scale,\n",
    "                undeformed_nugget=model_undeformed.nugget,\n",
    "                undeformed_var=model_undeformed.var,\n",
    "                deformed_range=model_deformed.len_scale,\n",
    "                deformed_nugget=model_deformed.nugget,\n",
    "                deformed_var=model_deformed.var\n",
    "            )\n",
    "        ) \n",
    "        ds = ds.rio.write_crs(\"EPSG:3413\")\n",
    "        \n",
    "        filename = f'{campaigns[0]}_{site}_krigged_MP_snow_depth.nc'\n",
    "        ds.to_netcdf(os.path.join(output_path, filename))\n",
    "        \n",
    "    print('File saved, done... ')\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
